# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a statistical simulation project comparing PLS-VIP (Partial Least Squares - Variable Importance in Projection) and RWA (Relative Weight Analysis) methods for identifying important predictors in regression models.

## Common Commands

### Running Simulations
```bash
# Run main simulation with default parameters
python main.py

# The simulation will:
# - Run 100 replications across multiple parameter combinations
# - Save results to simulation_results.csv
# - Display performance analysis
```

### Dependencies
```bash
# Install required packages
pip install -r requirements.txt
```

## Architecture

The codebase follows a modular design with clear separation of concerns:

- **Statistical Core (factors.py)**: Implements the two competing methods
  - `do_pls_vip()`: PLS-VIP scoring using cross-decomposition
  - `compute_rwa()`: Johnson's Relative Weight Analysis using transformation matrices
  - Data generation functions that create correlated predictors with controlled importance

- **Simulation Engine (main.py)**: Orchestrates Monte Carlo experiments
  - Uses fractional factorial design to test parameter combinations efficiently
  - Handles parallel replications with robust error recovery
  - Automatically analyzes results to determine which method performs better

- **Parameter Space**: The simulation tests across:
  - Sample sizes (100-500)
  - Number of predictors (10-50)
  - Correlation levels (0.1-0.5)
  - Effect magnitudes (0.1-0.5)
  - Noise ratios (0.1-0.5)
  - Importance proportion Î± (default 0.3)

## Development Notes

When modifying the simulation:
- The `alpha` parameter in main.py controls what proportion of variables are important (default 0.3)
- Set `randomize_important=True` to randomize which variables are important across replications
- Results are saved incrementally to prevent data loss from crashes
- The fractional factorial design reduces computational burden while covering the parameter space

## Output Files

The simulation generates several output files:

- **simulation_results.csv**: Raw simulation data with columns:
  - `n`: sample size
  - `J`: number of predictors
  - `magnitude`, `noise`, `rho`: simulation parameters
  - `method`: PLS or RWA
  - `top_k_acc`: accuracy for top-k predictions
  - `valid_run`: whether the simulation completed successfully

- **detailed_results.csv**: Aggregated performance metrics showing mean accuracies for top-1, top-2, and top-3 predictions

- **fractional_factorial_results.csv**: Results from fractional factorial design experiments

- **comparison_plot.png** and **performance_comparison.png**: Visual comparisons of method performance (generated by visualization.py)